0:00
Learn how to get chat GPT and other LLMs to give you the perfect responses by mastering prompt engineering strategies.
0:07
Anu Kubo is one of our most popular instructors. And in this course, she will teach you the latest techniques
0:13
to maximize your productivity with large language models. Hi everyone and welcome to this course on prompt engineering.
0:21
My name is Anu Kubo and I'm a software developer as well as course cruiser here on FreeCoCamp as well as on my own channel.
0:28
This is going to be a unique course for me as there is going to be a lot less coding going on
0:33
but a lot more understanding about the topic of prompt engineering and why some companies are paying up to $335,000 a year
0:42
according to Bloomberg for people in this profession. And no, no coding background is necessarily required.
0:48
So what are we waiting for? Let's do it. In this course, we will learn what prompt engineering
0:54
is exactly, get a brief introduction to AI, a look at large language models or LLMs
1:01
such as chat GPT, a look at text to image models such as mid journey, a look at emerging models.
1:07
This would include text to speech, text to audio or speech to text as well as prompt engineering mindset, best practices,
1:15
zero-shot prompting, few-shot prompting, chain of thought, AI hallucinations, vexes, text embeddings
1:22
and also end with a quick intro to chat GPT. So let's start off with looking at what exactly
1:29
prompt engineering is in the first place. Prompt engineering in a nutshell is a career
What is Prompt Engineering?
1:34
that came about of the back of the rise of artificial intelligence. It involves human writing, refining and optimizing prompts
1:41
in a structured way. This is done with the intention of perfecting the interaction between humans and AI to the highest degree possible.
1:49
Not only that, however, a prompt engineer is then also required to continuously monitor those prompts
1:55
ensure their effectiveness with time as AI progresses. Maintaining an up-to-date prompt library will be a requirement
2:02
that is placed onto the prompt engineer as well as reporting on findings and in general, being a thought leader in this space.
2:09
But why do we need it? And how did it come about from AI? Before moving on, let's actually make sure
2:15
we are on the same page about what exactly AI is. Artificial intelligence is the simulation
Introduction to AI
2:22
of human intelligence processes by machines. I say simulation as artificial intelligence
2:28
is not sentient, at least not yet anyways, meaning it cannot think for itself
2:33
as much as it may seem it does. Often, and this is certainly the case with tools such as chat GPT, for example, when we say AI,
2:43
we are simply referring to a term called machine learning. Machine learning works by using large amounts
2:48
of training data that is then analyzed for correlations and patterns. These patterns are then used to predict outcomes
2:56
based on the training data provided. So for example, here we are feeding data
3:01
saying that if a paragraph looks like this with this type of title, then it should be categorized
3:07
as international finance. The second paragraph should be put in the category of earning reports and so on.
3:14
With some code, we should be able to train our AI model to correctly guess what future paragraphs are about.
3:21
And that's it. Of course, that is a super basic example and we would need way more data
3:27
than these five paragraphs right here, but you get the idea. If you want to build your own AI model and understand the concept of machine learning better
3:34
as a total beginner, please check out my video on it on my channel, Code with Anya Kubo.
3:39
As of now, rapidly improving general AI techniques can create realistic text responses and even images, music, and other media
3:47
thanks to the huge amounts of training data and talented developers working on it today.
Why is Machine learning useful?
3:53
Why is prompt engineering useful? With the quick and exponential growing rise of AI,
3:59
even the architects of it themselves struggle to control it and its outputs. This might be a bit hard to understand,
4:06
but think of it this way. If you were to ask an AI chatbot what is four plus four,
4:11
you would expect it to say eight, right? The result of eight is pretty indisputable.
4:16
However, imagine you are a young student trying to learn the English language.
4:21
I'm going to show you just how different responses can be based on the prompts you feed
4:27
and in turn your learning experience. For this example, I'm going to be using Chat GPT's GPT-4 model.
4:34
So let's start with the basics. If you were to type, correct my paragraph
4:39
and then paste it a badly written paragraph. So just like this, today was great in the world for me.
4:45
I went to a Disneyland with my mom. It could have been better though if it wasn't raining. Great, the young English learner has a better sentence,
4:53
but it kind of stops there and the learner is just left to their own devices. And honestly, the sentence really isn't that great anyway.
5:02
What if the learner could get the best sentences possible from a teacher who understands their interests
5:08
to keep them engaged? With the correct prompts, we can actually create that with AI.
5:14
So let's give it a go and let's write a prompt to do this. So here's the prompt I'm going to give it.
5:20
I'm going to write, I want you to act as a spoken English teacher. I will speak to you in English
5:25
and you'll reply to me in English to practice my spoken English. I want you to keep my reply neat,
5:32
limiting the reply to 100 words. I also want you to strictly correct
5:37
my grammar mistakes and typos. And I want you to ask me a question in your reply.
5:43
Now, let's start practicing. You could ask me a question first. Remember, I want you to strictly correct
5:50
my grammar mistakes and typos. So there's my prompt. You can also go a step further
5:56
and ask it to correct your factual errors too, which I think would be an excellent addition to the prompt
6:01
that will benefit the young learner. Okay, so let's go ahead and add that to the prompt.
6:06
Okay, and let us do its thing. And great, so now this is way more interactive.
6:13
As you will see, it's asking you a question and telling you what to do and will provide you with corrections if needed.
6:19
So in a way, you're communicating with the AI. It's giving you suggestions and you're learning along the way.
6:26
It's a completely different experience thanks to the prompt that we wrote. Pretty cool, right?
6:31
We're gonna be diving into a bunch of these concepts soon, but first let's start with the basics.
Linguistics
6:37
Linguistics. Linguistics is the study of language. It focuses on everything from phonetics,
6:44
so the study of how speech sounds are produced and perceived. Phonology, so the study of sound patterns and changes.
6:51
Morphology, the study of word structure. Syntax, so the study of sentence structure.
6:57
Semantics, so the study of linguistic meaning. Pragmatics, so in other words, the study of how language is used in context.
7:05
Historical linguistics, or the study of language change. Sociolinguistics, or in other words,
7:12
the study of the relation between language and society. Computational linguistics,
7:18
so the study of how computers can process human language. And physiolinguistics,
7:23
or the study of how humans acquire and use language. So a lot.
7:29
Linguistics are the key to prompt engineering. Why? Understanding the nuances of language
7:35
and how it is used in different contexts is crucial for crafting effective prompts.
7:40
Not only that, but knowing how to use a grammar or language structure that is universally used
7:45
will result in the AI system returning back the most accurate results. As you can imagine,
7:51
the sheer amount of data that it is trained on is most likely to mostly use the standard grammar
7:58
and language structure that is universally used. So sticking to the standardization is key.
Language Models
8:04
Language models. Imagine a world where computers possess the power to understand and generate human language.
8:11
A world where machines can chat, write stories, and even compose poetry. In this magical realm,
8:18
language models can come into play. They are like the wizards of the digital realm
8:23
capable of understanding and creating human-like text. A language model is a clever computer program
8:31
that learns from a vast collection of written text. It takes in books, articles, websites,
8:36
and all sorts of written resources, allowing it to gather knowledge about how humans use language.
8:42
Just like a master linguist, it becomes an expert in the art of conversation, grammar, and style.
8:48
But how does this all work? Well, imagine you feed a sentence. The language model will then analyze the sentence,
8:55
examine the order of words, their meanings, and the way they fit together. Then the language model would generate a prediction
9:03
or a continuation of the sentence that makes sense based on its understanding of the language.
9:08
It will weave words together one by one, creating a response that seems like it was crafted
9:13
by a human being. Imagine having a conversation with the language model as if you were exchanging ideas with a digital friend.
9:20
You ask a question, and it responds with a well-crafted answer. You tell a joke, and it counters with a witty remark.
9:27
It's like having a language expert by your side always ready to assist and engage in conversation.
9:33
Now, you may wonder where these language models are used. They can be found in various places,
9:39
from your smartphone's virtual assistants to customer service chatbots, and even in the creative realm of writing.
9:46
They help us find information, offer suggestions, and create content. But remember, while language models
9:52
possess incredible abilities, they still rely on the human to create and train them.
9:58
They are, in fact, a fusion of human ingenuity and the power of algorithms, blending the best of both worlds.
10:05
Let's start off by looking at the history of language models, starting with the first AI, Eliza, back in the 60s.
10:12
Eliza is an early natural language processing computer program created from 1964 to 1966 at MIT by Joseph Wiesenbaum.
10:22
Eliza was designed to simulate a conversation with a human being. Eliza had a special knack for mimicking
10:28
a Rogerian psychotherapist, someone who essentially listens attentively and asks probing questions
10:35
to help people explore their thoughts and feelings. Eliza's secret weapon was its mastery of pattern matching.
10:42
It had a treasure trove of predefined patterns, each associated with specific responses.
10:47
These patterns were like magical spells that allowed Eliza to understand and respond to human language.
10:54
When you engage in a conversation with Eliza, it would carefully analyze your input, seeking patterns and keywords.
11:00
It would then transform your words into a series of symbols, searching for patterns that match those symbols
11:06
in its repertoire. Once a pattern was detected, Eliza would work its magic by transforming your words
11:12
into a question or statement that aimed to explore your thoughts and emotions. It was as if Eliza was holding up a metaphorical mirror,
11:20
encouraging you to delve deeper into your own thinking. For example, if you said something like, I feel sad,
11:27
Eliza would detect the pattern and respond with a question like, why do you think you feel sad?
11:33
It encouraged reflection and introspection, just like a caring therapist would.
11:39
But here's the delightful twist. Eliza didn't truly understand what you were saying.
11:44
It was just a clever illusion. It used pattern matching and some creative programming tricks
11:50
to create the illusion of understanding while in reality, it was just following a set of predefined rules.
11:57
Yet, even though Eliza was a simple program, people were often captivated by its conversational abilities.
12:04
They felt heard and understood, even if they knew they were talking to a machine. It was like having a digital confident
12:11
who was always ready to listen and offer gentle guidance. Eliza's creator, Weisenbaum,
12:17
intended the program as a method to explore communication between humans and machines. He was surprised and shocked that individuals,
12:24
including his secretary, attributed human-like feelings to the computer program.
12:29
But that is a whole other topic of conversation in itself. Eliza's impact was profound,
12:35
sparking interest and research in the field of natural language processing. It paved the way for more advanced systems
12:41
that could truly understand and generate human language. It was the humble beginning of a grand adventure
12:48
in the world of conversational AI. Fast forward to the 1970s, when a program named Shudlu appeared.
12:56
It could understand simple commands and interact with a virtual world of blocks. Although Shudlu wasn't a language model per se,
13:04
it laid the foundation for the idea of machines comprehending human language. But the true language models began around 2010,
13:12
when the power of deep learning and neural networks came into play. Enter the mighty GPT,
13:19
short for generative pre-trained transformer, ready to conquer the world of language.
13:24
In the year 2018, the fast iteration of GPT emerged, created by the company OpenAI.
13:31
It was trained on a large amount of text data, absorbing knowledge from books, articles,
13:36
and a large chunk of the internet. GPT-1 was a taste of things to come, an impressive language model,
13:42
but small compared to its descendants that we use today. As time went on, the saga continued with the arrival of GPT-2 in 2019,
13:51
followed by GPT-3 in 2020. This was a titan among language models
13:57
equipped with a large number of parameters, over 175 billion to be precise.
14:02
GPT-3 dazzled the world with its unparalleled ability to understand, respond, and even generate creative pieces of writing.
14:09
The arrival of GPT-3 marked a real turning point in terms of language models and AI.
14:15
At the time of writing, we now also have GPT-4, trained on pretty much the whole internet,
14:20
rather than outdated large data sets, as well as BERT from Google and so much more.
14:25
It would seem we are only just at the start when it comes to language models and AI. So learning how to harness this data with prompt engineering
14:32
is a smart move for anyone today. The prompt engineering mindset.
Prompt Engineering Mindset
14:38
When thinking of good prompts, it is always best to get in the correct mindset. Essentially, you want to just write one prompt, right?
14:45
And not have to waste time and tokens, writing lots of different prompts until you get the result you desire.
14:52
So essentially, kind of the same as when you Google stuff, right? How good are your Googling skills now,
14:58
as opposed to five years ago? I'm assuming a lot better. We have grown to intuitively know
15:04
what to type into Google the first time round as to not waste time. Having the same mindset for prompt engineering
15:11
can also be applied. Mahail Eric of the Infinite Machine Learning Podcast says it well when he says,
15:18
I personally like the analogy of prompting to designing effective Google searches. There are clearly better and worse ways to write queries
15:26
against the Google search engine that solve your task. This variance exists because of the opaqueness
15:32
of what Google is doing under the hood. We are gonna keep this in mind for the remainder of the course.
Using GPT-4
15:39
A quick intro to using chat GPT by OpenAI. So as I said in this course for the examples,
15:46
I will be using chat GPT's GPT for model. In order to follow along or just to understand
15:55
how we are going to be using the platform, please head over to openai.com
16:00
and just go ahead and sign up. I've already signed up, so I'm just gonna go ahead and log in
16:07
and that will take me to the platform in which I can choose what I want to interact with.
16:13
For this tutorial, we are going to be interacting with chat GPT for.
16:19
So please go ahead and click on here and that will take you to the platform.
16:24
And then I'm just gonna go ahead and switch to the GPT for model, which is the latest one.
16:31
Okay, so great. You will see here all the previous chats that I've had.
16:37
I'm just going to minimize this. And if we want to create a new chat, all we'd have to do is click the new chat button.
16:44
Okay, so here, for example, what I can do is just go ahead and ask any questions.
16:51
So what is four plus four? And then hit send. And that will essentially give me a response.
16:58
So I'm now interacting with chat GPT for. On this occasion,
17:03
I can actually build on the previous conversation. So what I can do is say, great.
17:11
Now, can you add another five to that?
17:19
What is the answer? And it will take into account everything
17:24
that I have previously. Okay, I am building on top of the knowledge that it already has.
17:30
Great. So again, this is just a very quick introduction to how to use this,
17:36
we will be doing a deeper dive into this throughout this course. So once again, to create a new chat,
17:43
all you'd have to do is create new chat. And if you want to delete the old one, just go ahead and click that delete button.
17:48
And that will delete it. And then a new chat is brought up automatically.
17:53
Wonderful. Now you might have seen my course on open AI in which we can also use the API.
18:02
And to use the API, just go over to the API references. And all you would have to do is get an API key.
18:10
And the API key can be viewed here. And then you just go ahead and create an API key.
18:16
And that will allow you to interact with the open AI API in order for you to build out your own platforms
18:24
just as the one we saw before. So if you're interested in that, please do head over to my tutorial on this,
18:31
again, on the free COCAM channel. Otherwise, let's continue using chat GPT.
18:38
So once again, I'm just going to log in and head back to the platform here. And that is it, we are ready to go.
18:47
Another thing I want to discuss is tokens. As you might find that you have run out of the free tokens
18:55
that you have in order to interact with chat GPT. So in order to do that, I'm just going to show you this,
19:02
I'm going to head over to the documentation and talk to you a little bit about tokens.
19:09
So GPT-4 essentially processes all texts in chunks called tokens.
19:16
And this token is approximately four characters or 0.75 words for English text.
19:24
And we essentially get charged by token. If you want to know exactly how many tokens you are using,
19:31
you can check it out here, you can check out the tokenizer tool, and it will give you a rough example.
19:37
So for example, I can say, what is four plus four.
19:44
And with that piece of text, the total count of tokens is going to be six.
19:51
Okay, so there we go. That is exactly how many tokens will be used
19:56
in order to produce a answer for this request.
20:02
Great, so here is a URL for that. You can play around with it. I hope you have fun.
20:08
If you want to see your usage, you can head over to account and then you can manage your account.
20:14
And this should be able to show you your usage. So it will show you your usage right here per month.
20:21
And then you can, of course, also add billing in order to carry on using chat GPT
20:28
in case you've used up all your tokens and you can't use it anymore. So once again, this is under account billing overview.
20:36
So just go check it out. Okay, and now back to the platform.
Best practices
20:42
Best practices. The biggest misconception when it comes to prompt engineering
20:48
is that it's an easy job with no science to it. I imagine a lot of people think
20:53
it's just about constructing a one-off sentence such as correct my paragraph that we saw in the previous example.
21:00
When you start to look at it, creating effective prompts relies on a bunch of different factors.
21:06
Here are some things to consider when writing a good prompt. Consider writing clear instructions
21:12
with details in your query. Consider adopting a persona as well as specifying the format
21:19
using iterative prompting, meaning if you have a multi-part question or if the first response wasn't sufficient,
21:26
you can continue by asking follow-up questions or asking the model to elaborate and avoid leading the answer.
21:33
Try not to make your prompts so leading that it inadvertently tells the model what answer you're expecting.
21:39
This might bias the response unduly. And finally, limit the scope for long topics.
21:45
If you're asking about a broad topic, it's helpful to break it down or limit the scope to get a more focused answer.
21:51
Let's look at some of these now. In order to write clearer instructions, we can adopt writing more details in our queries.
21:59
And to get the best results, don't assume the AI knows what you are talking about.
22:04
Writing something like, when is the election, implies that you are expecting the AI to know
22:10
what election you are talking about and what country you mean. This may result in you asking a few follow-up questions
22:17
to finally get the result you want, resulting in time loss and frankly, perhaps some frustration.
22:23
Consider taking the time to write a prompt with clear instructions. So, for example, instead of writing,
22:30
when is the election, you could write, when is the next presidential election for Poland?
22:36
So let's go ahead and run this. And this will be much more precise
22:41
and knows exactly what we are asking about. It's not gonna go guessing and waste our time
22:48
as well as waste our resources. So in other words, tokens that we are using, so in other words, money,
22:54
in order to get the right answer the first time. Here are some other examples of how you could write clearer prompts.
23:01
So for example, we have this prompt here, which says write code to filter out the ages from data.
23:07
And if you run it, you don't really know what language it's gonna come back with, let's see. So for example, here it's using Python.
23:15
I actually didn't wanna use Python, okay? So now we've lost some tokens asking this.
23:21
We've also lost some time and we just haven't got the right response. This could have been so easily avoided.
23:28
So I'm gonna stop this from generating and let's try again. So this time, let's be more specific by writing,
23:36
write a JavaScript function that will take an array of objects and filter out the value of age property
23:42
and put them in a new array. Please explain what each code snippet does. In this example, I am not assuming the AI knows
23:50
what computer language I like to use and I am being more specific about what my data actually looks like.
23:56
On this occasion, it's an array of objects. Not only that, I'm also asking the AI
24:02
to explain why it's doing each step so that I in turn can understand and not just copy paste the code
24:08
without gaining any knowledge from it. Okay, so here you can see a live example of what's coming back to us from GPT-4.
24:17
It's given us the correct code. So I have checked that and I was also giving us an example
24:24
of how you would use the function, which is something I didn't ask, which is super useful. It's kind of gone above and beyond
24:30
for helping me out in understanding what is going on.
24:35
Let's look at another example. We can write, tell me what this essay is about.
24:41
So I'm going to just type this and then just paste in an essay and hit go. And then chat GPT will do its thing.
24:49
It's going to give me a summarization as it thinks best. So on this occasion,
24:55
it is essentially giving me numbered points about what this essay is about.
25:00
They're really long. I really didn't want to read this much. It's pretty much looking to be the same
25:06
as the original essay. So this is not something I wanted. I should have been way more specific
25:13
in telling it what I need. So what I'm going to do is just add to this conversation.
25:19
So it's going to learn on what I wrote previously. And I'm just going to specify to use bullet points
25:24
to explain what this essay is about, making sure each point is no longer the 10 words long.
25:30
So I am being super specific in providing the instructions of what I want
25:37
and let's hit go. So now this is a lot shorter. Okay, as you can see, each point is no longer than 10 words long.
25:44
And then I'm going to get a summary that is a bit longer and will give me a summary of the essay
25:51
that I pasted in above. So great, of course you can do this
25:57
on any essay or piece of text that you wish and you can set your own clear
26:03
and specific instructions as well. Okay, so I hope you can see
26:08
why the second one is better. It's because I am not assuming the AI knows what kind of format I want the summarization
26:15
of the essay to be in. I am being specific that I want very short notes
26:20
on the essay in bullet point format with a short conclusion at the end. If I did not put this,
26:26
the summary could have been just as long as the essay itself and the prompt could be considered useless in my eyes.
26:34
Next up, we can also adopt a persona. When writing prompts, it is sometimes helpful to create a persona.
26:40
This means you're asking the AI to respond to you and a certain character. So exactly like the English language teacher example
26:47
we saw earlier, using a persona in prompt engineering can help ensure that the language model's output
26:53
is relevant, useful and consistent with the needs and preferences of the target audience,
26:59
making it a powerful tool for developing effective language models that meet the needs of users.
27:05
Let's look at some examples of adopting a persona. So for example, you're gonna have this prompt right here.
27:12
Write a poem for a sister's high school graduation that will be read out to a family and close friends.
27:19
So let's go ahead and run this and let's see what comes back.
27:24
So there we go. It is quite good in a room filled with kin and close ties.
27:29
We gathered to honor the mist in our eyes for a journey has ended another begun as our dear sister steps into the sun.
27:36
Okay, so it's coming out with a poem I can see here. It is quite a good one, I guess,
27:43
probably better than anything that I would have written. And it is maybe a little bit generic.
27:50
Maybe that's what you wanted. I think we can do better than this. So let's try this.
27:56
This time I'm gonna write a prompt with a persona. So this time I'm gonna specify who I'm writing as.
28:03
I'm gonna do write a poem as Helena.
28:09
Helena is 25 years old and an amazing writer.
28:18
Her writing style is similar to famous
28:24
21st century poet Rupi Kaur. Writing as Helena, write a poem for her 18 year old sister
28:44
to celebrate her sister's high school graduation. High school graduation, this will be read out to friends
29:00
and family at the gathering.
29:06
Okay, so let's check it out now. We're writing as Helena, she's 25, she's an amazing writer
29:14
and we've also assigned a writing style. So let's check it out. Now Chat GPT should be using anything it knows about
29:23
Rupi Kaur, hopefully from the internet, in order to apply that style to this poem.
29:29
Okay, and as you can see, this is maybe a little bit more affectionate. We've said sister, it's obviously a younger sister,
29:37
so the words little sister are being used. And in general, I think this is a much higher quality poem
29:45
and if Helena truly does have the style of Rupi Kaur in writing, it will be almost indistinguishable
29:52
who wrote this poem, Chat GPT or Helena. So here we go, here's the full thing.
29:58
It starts off, in the garden of our youth, I watch you bloom from bud to blossom, from child to woman, 18 summers passed.
30:06
Again, utilizing the fact that we fed it, she was 18 and every winter's chill only made you stronger,
30:13
a force of nature still. So yes, in my eyes, this poem is a lot more better
30:18
it's much more refined, it's much more personal, thanks to the prompts that we wrote.
30:24
We've already had a brief look at specifying format when we limited the word count of our bullet points
30:30
in a previous example. So that was a great example, limiting words is one that I use often.
30:37
However, we can do a bunch of other things, including specifying if something is a summary,
30:44
a list or a detailed explanation. Heck, you can even create checklists.
30:49
So I'm going to go ahead and show you how to do this. Here is an example prompt and I'm just going to run it.
30:56
And there we go, we have created a checklist. So many things you can do in Chat GPT.
31:05
Just make sure to specify the type of format you want and it should be able to do it.
31:13
Okay, great. Now that we looked at some best practices, let's move on to some more advanced topics
31:19
in the prompt engineering. In this section, I'm going to talk about two types of prompting we can do, zero-shot prompting
Zero shot and few shot prompts
31:27
and few-shot prompting. Zero-shot prompting leverages a pre-trained model's understanding of words and concept relationships
31:34
without further training. And few-shot prompting enhances the model with training examples via the prompt avoiding retraining.
31:42
So essentially in the context of the GPT-4 model, we don't really need to do much.
31:48
We are already using all of the data that it has in order to ask when is Christmas in America?
31:53
So let's go ahead and do some zero-shot prompting. When is Christmas in America?
32:03
And here, go. Okay, so it clearly already has the data for this.
32:10
We don't need to add any examples or anything like that. So as you can see, zero-shot prompting refers
32:17
to a way of querying models like GPT without any explicit training examples
32:23
for the task at hand. In the context of machine learning and not just GPT,
32:29
zero-shot typically means that a model performs a task without having seen any examples
32:35
of that task during its training. Okay, great.
32:40
So now let's look at few-shot prompting. So once again, with zero-shot prompting,
32:46
we gave our language model a prompt and got a response. But sometimes that's just not enough
32:52
and we need a bit more training. So let's use few-shot prompting and level up our language model by showing a few examples
33:00
of the tasks we want it to perform. So instead of zero examples, we give it a tiny bit of data.
33:07
So let's think, what would GPT for not know?
33:12
I guess it would not know my favorite types of food. So for example, let's check,
33:18
what is Ania's favorite type of food?
33:26
Plural, okay. And I mean, it can guess, but no, it's just telling me that it doesn't know.
33:34
So that is absolutely fine, let's stop generating. So now let's feed it in some example data.
33:40
I'm gonna feed it in a tiny bit of data. Ania's favorite type of food includes,
33:51
sorry about my English. Let's go with burgers, fries, I love fries, pizza,
34:01
and hit enter, okay? So we are essentially giving chat GPT some information.
34:09
So now if I type what restaurant should I take Ania
34:17
to in Dubai this weekend and hit here,
34:26
it should hopefully understand that my favorite types of foods are burgers, fries, and pizza, and given that find me some restaurants
34:35
in Dubai that I would like to go to. So here are some, this has been updated as of September,
34:42
2021, but you know, these are pretty good ones. So I would totally go to these.
34:48
This is a great example of few shop prompting in which it wouldn't have been able to answer this question
34:55
if I hadn't had given it some example data or just trained the model a little bit more
35:02
in order to get the response that I want. Great, AI hallucinations.
AI hallucinations
35:09
Now we're delving into something you probably never thought you'd hear in an AI context and that's hallucinations.
35:16
So what exactly are AI hallucinations? And no, they're not when your AI assistants
35:22
start seeing unicorns and rainbows. It's actually a time that refers to the unusual outputs
35:28
that AI models can produce when they misinterpret data. A prime example of this is Google's Deep Dream.
35:36
You know, that project that turns pictures of your dog into a nightmarish blend of dog faces
35:41
and well, more dog faces. Deep Dream is an experiment that visualizes the patterns
35:47
learned by a neural network. It is built to over interpret and enhance the patterns
35:52
it sees in an image, or in other words, fill in the gaps with images.
35:58
But some of the time those gaps can be filled with the wrong thing. This is an example of an unusual output
36:05
that AI models can produce when they misinterpret data. Now, why do these hallucinations happen, you ask?
36:13
They're trained on a huge amount of data and they make sense of new data based on what they've seen before.
36:20
Sometimes, however, they make connections that are, let's call it creative.
36:26
And voila, an AI hallucination occurs. Despite their funny results,
36:31
AI hallucinations aren't just entertaining. They're also quite enlightening. They show us how our AI models interpret
36:38
and understand data. It's like a sneak peek into their thought processes.
Vectors/text embeddings
36:43
This example is actually an AI image hallucination, as I thought it would be a fun one to show.
36:49
AI hallucinations can also happen with text models. An example of this is us asking a text model
36:55
about a historical figure and the text model not having an answer and hallucinating one instead,
37:00
resulting in an inaccurate response. Vectors and text embeddings.
37:06
To finish off, I'm going to leave you with a slightly more complex subject. We're going to take a quick look
37:12
at the topic of text embedding and vectors. In computer science, particularly in the realm of machine learning
37:19
and natural language processing or NLP, text embedding is a popular technique
37:24
to represent textual information in a format that can be easily processed by algorithms, especially deep learning models.
37:31
In the context of prompt engineering, LLM embedding refers to representing prompts in a form that the model can understand and process.
37:39
This involves converting the text prompt into a high dimensional vector that captures its semantic information.
37:46
So essentially the word food is represented by this. If using the create embedding API from open AI.
37:53
Okay, so you will see it's represented, the word was represented by an array of lots and lots of numbers.
38:00
But why do this? Well, think about it this way. If you ask a computer to come back
38:06
with a similar word to food, you wouldn't really expect it to come back with burger or pizza, right?
38:12
That's what a human might do when thinking of similar words to food. A computer would more likely look
38:18
at the word lexicographically, kind of like when you scroll through a dictionary and come back with foot, for example.
38:26
This is kind of useless to us. We wanna capture a word's semantic meaning.
38:31
So the meaning behind the word. Text embeddings do essentially that, thanks to the data captured in this super long array.
38:40
Now, I can find words that are similar to food in a large corpus of text
38:46
by comparing text embedding to text embedding and returning the most similar ones.
38:51
So words such as burger instead of foot will be more similar.
38:56
To create a text embedding of a word or even a whole sentence, check out the create embedding API here from OpenAI.
39:05
So here's the URL that you should visit and to create your own text embedding,
39:10
you're gonna have to create a post request to this endpoint. Okay, so that's what you can do.
39:17
You can also take the code from here. So this is an example request written in Node.js
39:25
and you would have to install the OpenAI package, take these two methods from it
39:33
in order to pass through your OpenAI API key that I showed you how to get earlier.
39:39
As a refresher, you should go here and view API keys to create your own API key.
39:45
And once you pass that through, you can then use the configuration
39:51
and pass it through here in order to use OpenAI and all of its wonderfulness,
39:57
including the create embedding method in which you pass through an object.
40:02
That object has to include the model and it also is gonna include the input. So in this case, it is the text
40:10
that you want to turn into an embedding. So this is the code for doing that.
40:16
And here is the response, which comes back as an object. And then you would use dot notation to get the data,
40:24
go into the array in order to get the embedding. So this is gonna be the embedding that we saw earlier.
Recap
40:31
It's an array made up of numbers and a lot of these numbers, okay?
40:37
So not just these three, this does spill out and this will be a very, very long array of numbers
40:44
that will give you this semantic meaning of whatever text you pass through, okay?
40:50
So please have a go at playing around with this API in order to create your own text embeddings
40:57
and compare them against other texts embeddings in order to find similar text.
41:02
And that's it. Thank you so much for watching this course on prompt engineering
41:08
in which we covered what it is. We covered an introduction to AI as well as looked at linguistics, language models,
41:15
prompt engineering mindset, using GPT-4, how to look at best practices
41:20
as well as zero shot and few shot prompting, as well as AI hallucinations, vectors or texts embeddings
41:27
and this recap right here. So I hope you've enjoyed it and I'll see you again on the FreeCocam channel.